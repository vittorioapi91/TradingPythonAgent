# TradingPythonAgent

A comprehensive Python platform for financial data collection, storage, and machine learning modeling. This project provides end-to-end infrastructure for downloading, storing, and analyzing financial and economic data from multiple sources, with built-in ML workflows for macro cycle modeling.

## ğŸ¯ Overview

TradingPythonAgent is a production-ready system that:

- **Downloads** financial and economic data from multiple authoritative sources
- **Stores** data in PostgreSQL databases with environment-aware configuration
- **Models** macro economic cycles using Hidden Markov Models (HMM)
- **Tracks** ML experiments with MLflow
- **Serves** models via KServe
- **Monitors** with Prometheus and Grafana
- **Orchestrates** workflows with Kubeflow Pipelines
- **Deploys** via Jenkins CI/CD with branch-aware environments

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Data Collection Layer                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  EDGAR (SEC) â”‚ FRED â”‚ BLS â”‚ BIS â”‚ Eurostat â”‚ IMF â”‚ Yahoo   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PostgreSQL Storage Layer                    â”‚
â”‚  (Environment-aware: dev/test/prod databases)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ML Pipeline Layer                         â”‚
â”‚  HMM Models â”‚ MLflow â”‚ Feast â”‚ KServe â”‚ Kubeflow             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Monitoring & Deployment                     â”‚
â”‚  Prometheus â”‚ Grafana â”‚ Jenkins CI/CD                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ Project Structure

```
TradingPythonAgent/
â”œâ”€â”€ src/                              # Application source code
â”‚   â”œâ”€â”€ config.py                    # Environment configuration
â”‚   â”œâ”€â”€ fundamentals/                 # Company fundamentals data
â”‚   â”‚   â”œâ”€â”€ edgar/                   # SEC EDGAR filings downloader
â”‚   â”‚   â””â”€â”€ download_logger.py       # Download error logging
â”‚   â”œâ”€â”€ macro/                       # Macroeconomic data sources
â”‚   â”‚   â”œâ”€â”€ fred/                    # Federal Reserve Economic Data
â”‚   â”‚   â”œâ”€â”€ bls/                     # Bureau of Labor Statistics
â”‚   â”‚   â”œâ”€â”€ bis/                     # Bank for International Settlements
â”‚   â”‚   â”œâ”€â”€ eurostat/                # Eurostat (EU statistics)
â”‚   â”‚   â””â”€â”€ imf/                     # International Monetary Fund
â”‚   â”œâ”€â”€ markets/                     # Market data
â”‚   â”‚   â”œâ”€â”€ equities/                # Stock market data (Yahoo Finance)
â”‚   â”‚   â””â”€â”€ etf/                     # ETF data (iShares)
â”‚   â”œâ”€â”€ model/                       # ML modeling
â”‚   â”‚   â”œâ”€â”€ hmm_model.py             # Hidden Markov Model for macro cycles
â”‚   â”‚   â”œâ”€â”€ data_loader.py           # Data loading from PostgreSQL
â”‚   â”‚   â”œâ”€â”€ training_script.py       # Training pipeline
â”‚   â”‚   â””â”€â”€ config.yaml              # Model configuration
â”‚   â”œâ”€â”€ mlflow.py                    # MLflow integration
â”‚   â”œâ”€â”€ feast.py                     # Feast feature store
â”‚   â”œâ”€â”€ kserve.py                    # KServe model serving
â”‚   â”œâ”€â”€ kubeflow.py                  # Kubeflow pipelines
â”‚   â””â”€â”€ prometheus.py                # Prometheus metrics
â”œâ”€â”€ src/                             # Application code (see above)
â”œâ”€â”€ tests/                          # Test suite
â”œâ”€â”€ requirements*.txt               # Python dependencies
â””â”€â”€ README.md                        # This file

**Note**: Infrastructure components (Docker, Kubernetes, Jenkins, etc.) have been moved to a separate repository: [infra-platform](https://github.com/your-org/infra-platform)
â”œâ”€â”€ .env.dev                         # Development environment config
â”œâ”€â”€ .env.staging                     # Staging environment config
â”œâ”€â”€ .env.prod                        # Production environment config
â”œâ”€â”€ Jenkinsfile                      # CI/CD pipeline
â”œâ”€â”€ requirements.txt                 # Base Python dependencies (shared)
â”œâ”€â”€ requirements-dev.txt             # Development dependencies (dev/* branches)
â”œâ”€â”€ requirements-staging.txt         # Staging dependencies (staging branch)
â”œâ”€â”€ requirements-prod.txt            # Production dependencies (main branch)
â””â”€â”€ README.md                        # This file
```

## ğŸ”Œ Data Sources

### Fundamentals

- **SEC EDGAR**: Company filings (10-K, 10-Q, 8-K, etc.) with XBRL support
  - Downloads all company filings from SEC EDGAR database
- **Company Data**: Ticker symbols, SIC codes, entity types

### Macroeconomic Data

- **FRED** (Federal Reserve Economic Data): US economic time series
- **BLS** (Bureau of Labor Statistics): US labor market statistics
- **BIS** (Bank for International Settlements): International banking statistics
- **Eurostat**: European Union statistics
- **IMF**: International Monetary Fund economic data

### Market Data

- **Yahoo Finance**: Stock prices, historical data, extended market data
- **iShares ETFs**: ETF holdings, details, and performance data

## ğŸ—„ï¸ Database Architecture

The project uses PostgreSQL databases with environment-aware configuration:

- **Development** (`dev/*` branches): `dev.tradingAgent@localhost:5432`
- **Staging** (`staging` branch): `test.tradingAgent@localhost:5432`
- **Production** (`main` branch): `prod.tradingAgent@localhost:5432`

Each environment has separate databases:
- `edgar` - SEC EDGAR filings
- `fred` - FRED economic data
- `bls` - BLS labor statistics
- `bis` - BIS banking data
- `eurostat` - Eurostat data
- `imf` - IMF data

## ğŸ¤– Machine Learning

### Hidden Markov Model (HMM) for Macro Cycles

The project includes a complete ML workflow for modeling macro economic cycles:

- **Model**: Multi-regime HMM using Pyro (2, 3, or 4 regimes)
- **Features**: Time series transformations (percentage changes, differences)
- **Training**: Expectation-Maximization algorithm
- **Evaluation**: Log-likelihood, AIC, BIC metrics
- **Serving**: KServe deployment for real-time inference
- **Tracking**: MLflow experiment tracking
- **Feature Store**: Feast for online feature serving

See [`src/model/README.md`](src/model/README.md) for detailed ML documentation.

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+ (Python <3.12 for KServe support)
- PostgreSQL 15+
- Docker and Docker Compose (for monitoring services)
- Git

### Installation

1. **Clone the repository**:
   ```bash
   git clone https://github.com/vittorioapi91/TradingPythonAgent.git
   cd TradingPythonAgent
   ```

2. **Create virtual environment**:
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies** (environment-specific):
   ```bash
   # The system automatically detects your environment based on git branch
   # For manual installation, use the appropriate file:
   pip install -r requirements-dev.txt      # For dev/* branches
   pip install -r requirements-staging.txt  # For staging branch
   pip install -r requirements-prod.txt     # For main branch
   
   # Or use the config module to get the right file:
   python -c "from src.config import get_requirements_file; print(get_requirements_file())"
   ```

4. **Configure environment**:
   - The system automatically detects your git branch and loads the appropriate `.env` file
   - For manual configuration, copy `.env.dev` and update with your credentials:
     ```bash
     cp .env.dev .env.local
     # Edit .env.local with your database credentials
     ```

5. **Start PostgreSQL** (if using Docker):
   ```bash
   # Infrastructure services are in the infra-platform repository
   # Clone and start services from: https://github.com/your-org/infra-platform
   cd ../infra-platform/.docker
   docker-compose -f docker-compose.infra-platform.yml up -d postgres
   ```

6. **Start monitoring services** (optional):
   ```bash
   # From the infra-platform repository
   cd ../infra-platform/.docker
   ./start-docker-monitoring.sh
   # Or manually:
   docker-compose -f docker-compose.infra-platform.yml up -d grafana prometheus mlflow
   ```

### Environment Configuration

The project uses environment-aware configuration that automatically detects your git branch:

- **`dev/*` branches** â†’ Loads `.env.dev` â†’ Uses `dev.tradingAgent@localhost`
- **`staging` branch** â†’ Loads `.env.staging` â†’ Uses `test.tradingAgent@localhost`
- **`main` branch** â†’ Loads `.env.prod` â†’ Uses `prod.tradingAgent@localhost`

Environment variables are loaded automatically when the package is imported. See [`src/config.py`](src/config.py) for details.

## ğŸ“– Usage Examples

### Download SEC EDGAR Filings

```bash
# Generate catalog of companies and filings
python -m src.fundamentals.edgar \
    --generate-catalog \
    --download-companies \
    --start-year 2020

# Download filings from database
python -m src.fundamentals.edgar \
    --from-db \
    --ticker AAPL,MSFT,NVDA
```

### Download FRED Economic Data

```bash
# Generate database with all downloadable series
python -m src.macro.fred.main \
    --generate-db \
    --api-key YOUR_FRED_API_KEY

# Download specific series
python -m src.macro.fred.main \
    --series GDP UNRATE CPIAUCSL \
    --start-date 2000-01-01
```

### Download BLS Labor Statistics

```bash
python -m src.macro.bls.main \
    --api-key YOUR_BLS_API_KEY \
    --series CUUR0000SA0 \
    --start-year 2020
```

### Train HMM Model

```bash
cd src/model
python training_script.py \
    --series-ids GDP UNRATE CPIAUCSL \
    --start-date 2000-01-01 \
    --n-regimes 4 \
    --mlflow-tracking-uri http://localhost:55000
```

### Download Stock Market Data

```bash
python -m src.markets.equities.main \
    --tickers AAPL,MSFT,GOOGL \
    --start-date 2020-01-01 \
    --end-date 2024-01-01
```

## ğŸ”§ Configuration

### Environment Variables

Create `.env.dev`, `.env.staging`, or `.env.prod` files with:

```bash
# PostgreSQL Configuration
POSTGRES_USER=dev.tradingAgent
POSTGRES_HOST=localhost
POSTGRES_PASSWORD=your_password
POSTGRES_PORT=5432

# API Keys
FRED_API_KEY=your_fred_api_key
BLS_API_KEY=your_bls_api_key

# MLflow
MLFLOW_TRACKING_URI=http://localhost:55000
```

### Database Setup

The system automatically creates database schemas when first connecting. Ensure PostgreSQL is running and accessible.

## ğŸ­ CI/CD Pipeline

The project includes separate Jenkins CI/CD pipelines for application code and infrastructure:

### Application Pipeline (`Jenkinsfile`)
- **Purpose**: Builds and validates trading_agent application code
- **Triggers**: On all code changes in this repository
- **Stages**:
  - JIRA validation (for feature branches)
  - Module validation
  - Airflow DAG validation (syntax/imports)
  - Unit tests
  - Docker image builds
  - Kubernetes deployments

### Infrastructure Pipeline
- **Repository**: [infra-platform](https://github.com/your-org/infra-platform)
- **Purpose**: Validates and builds infrastructure components
- **Triggers**: On infrastructure repository changes
- **Stages**:
  - Infrastructure configuration validation
  - Docker image builds (e.g., jenkins-custom)
  - Service validation

**Note**: Infrastructure CI/CD is managed in the separate `infra-platform` repository.

**Branch-aware deployments:**
- **Feature branches** (`dev/{jira_issue}/{project}-{subproject}`): Deploy to dev environment
- **Staging branch**: Deploy to staging environment
- **Main branch**: Deploy to production

See [`JENKINS.md`](JENKINS.md) for detailed Jenkins configuration.

### Branch Naming Convention

Feature branches must follow the pattern:
```
dev/{JIRA_ISSUE}/{project}-{subproject}
```

Examples:
- `dev/DEV-4/trading_agent-fundamentals`
- `dev/PROJ-123/trading_agent-macro`
- `dev/BUG-789/trading_agent-model`

**Important**: The Jenkins pipeline automatically validates branch names and JIRA issues:

- **Branch Name Validation**: The pipeline extracts the JIRA issue key (e.g., `DEV-4`) from the branch name using the pattern `dev/{JIRA_KEY-NUMBER}/{project}-{subproject}`
- **JIRA Issue Validation**: For feature branches, the pipeline:
  - Tests JIRA connection and authentication
  - Validates that the JIRA issue exists and is accessible
  - If validation fails, the pipeline continues with a warning (non-blocking)

### Commit Message Requirements

**All commit messages must include the JIRA issue key** in the format `[JIRA_ISSUE]` at the beginning of the commit message.

Examples:
- `[DEV-4] Add EDGAR download functionality`
- `[PROJ-123] Fix database connection issue`
- `[DEV-4] Update README with JIRA validation info`

The JIRA issue key in the commit message should match the one in the branch name. This ensures proper tracking and linking between commits and JIRA issues.

## ğŸ“Š Monitoring

### Prometheus Metrics

Metrics are exported at `http://localhost:8000/metrics`:
- Model predictions and latency
- Regime distributions
- Model performance (AIC, BIC, log-likelihood)

### Grafana Dashboards

Access Grafana at `http://localhost:3000` (admin/admin):
- Model monitoring dashboard
- Regime analysis dashboard
- Data pipeline metrics

### MLflow Tracking

Access MLflow UI at `http://localhost:55000`:
- Experiment tracking
- Model versioning
- Parameter and metric logging

## ğŸ§ª Testing

```bash
# Run tests
pytest tests/

# Run with coverage
pytest --cov=trading_agent tests/
```

## ğŸ“š Documentation

- **ML Modeling**: [`trading_agent/model/README.md`](trading_agent/model/README.md)
- **Jenkins CI/CD**: [`JENKINS.md`](JENKINS.md)
- **Infrastructure**: See [infra-platform](https://github.com/your-org/infra-platform) repository for Docker, Kubernetes, and infrastructure setup

## ğŸ› ï¸ Development

### Adding a New Data Source

1. Create a new module in `trading_agent/macro/` or `trading_agent/markets/`
2. Implement downloader class with PostgreSQL integration
3. Add database schema initialization
4. Create main entry point script
5. Update this README

### Code Style

- Follow PEP 8
- Use type hints
- Document all public functions and classes
- Add docstrings to modules

## ğŸ” Security

- **Never commit** `.env` files (they're in `.gitignore`)
- Use environment-specific database users
- Store API keys in environment variables or secure credential stores
- Use different credentials for dev/staging/prod environments

## ğŸ“ License

[Add your license here]

## ğŸ¤ Contributing

1. Create a feature branch following the naming convention: `dev/{JIRA_ISSUE}/{project}-{subproject}`
2. Ensure the JIRA issue exists before pushing
3. Make your changes
4. Test thoroughly
5. Submit a pull request

## ğŸ› Troubleshooting

### Database Connection Issues

- Verify PostgreSQL is running: `docker ps | grep postgres`
- Check environment variables are loaded: `python -c "import os; print(os.getenv('POSTGRES_USER'))"`
- Verify database user exists: `docker exec postgres psql -U tradingAgent -c "\du"`

### Import Errors

- Ensure you're in the project root directory
- Activate virtual environment
- Install all dependencies: `pip install -r requirements.txt`

### Jenkins Pipeline Issues

- Check branch naming follows convention
- Verify JIRA issue exists
- Check Jenkins logs for detailed error messages

## ğŸ“ Support

For issues or questions:
1. Check the relevant module's documentation
2. Review Jenkins build logs
3. Check database and service logs
4. Review GitHub issues

## ğŸ¯ Roadmap

- [ ] Additional data sources
- [ ] Real-time data streaming
- [ ] Advanced ML models
- [ ] Web UI for data exploration
- [ ] API endpoints for data access

---

**Built with**: Python, PostgreSQL, PyTorch, MLflow, Feast, KServe, Kubeflow, Prometheus, Grafana, Jenkins
